{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "genAugs_onthefly.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "f6a07eb392eec90936ba3a5d2c0ea46bee5ece6e1476aff4233cfb38874a8039"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbTkUprLIz9G"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import torchsummary\n",
        "import copy\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P-Hlw2OJeUc",
        "outputId": "820f3e3a-f960-438e-8875-aa8dccbb8765"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m63ebfAVxMQY",
        "outputId": "c75d018f-8d50-47c1-a153-63233c2ddd89"
      },
      "source": [
        "# Colab specific data loading\n",
        "\n",
        "# In Google Drive, create a shortcut link of the shared Project folder so that it appears in your root Google Drive directory\n",
        "# i.e., Right Click Project folder: \"Add Shortcut to Drive\"\n",
        "\n",
        "%cd '/gdrive/MyDrive/Project/'\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/.shortcut-targets-by-id/1ONXXjIHVMg4MHpAdUIdbB4Fr9W33JPYU/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ATrS7kRFbVg"
      },
      "source": [
        "# # Data should be in a dir named 'data/'\n",
        "data = np.load('data/RESISC45_images.npy')\n",
        "labels = np.load('data/RESISC45_classes.npy')\n",
        "classes = np.load('data/RESISC45_class_names.npy')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AlXorlebOvZ",
        "outputId": "be99f3ca-1d76-4d8c-b1bb-515e615dde21"
      },
      "source": [
        "\n",
        "print('Training data shape: ', data.shape)\n",
        "print('Testing data shape: ', labels.shape)\n",
        "print('Num Classes', classes.shape)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape:  (31500, 256, 256, 3)\n",
            "Testing data shape:  (31500,)\n",
            "Num Classes (45,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhwY3ieSJkqO"
      },
      "source": [
        "\n",
        "class addGaussianNoise(object):\n",
        "    # Transform to add gaussian noise since PyTorch did not have one (that I know of).\n",
        "    def __init__(self, mean=0.0, std=1.0, p=0.5):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.p = p\n",
        "      \n",
        "    def __call__(self, img):\n",
        "        if torch.rand(1).item() < self.p:\n",
        "            return img + torch.randn(img.size()) * self.std + self.mean\n",
        "        return img\n",
        "        \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1}, p={2})'.format(self.mean, self.std, self.p)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb4gUZzoU_fr"
      },
      "source": [
        "\n",
        "# set augmentation parameters for input task\n",
        "def makeAugParams(task):\n",
        "\n",
        "    # Reduced list - dropped perspective and blur\n",
        "    pHF = 0.99 if task[0] == 1 else 0.0\n",
        "    pVF = 0.99 if task[1] == 1 else 0.0\n",
        "    rotAng = 359.0 if task[2] == 1 else 0.0\n",
        "    cropScale = 0.5 if task[3] == 1 else 1.0\n",
        "    pNoise = 0.99 if task[4] == 1 else 0.0\n",
        "    satVal = 4.0 if task[5] == 1 else 0.0\n",
        "    brightVal = 0.5 if task[6] == 1 else 0.0\n",
        "    contrastVal = 0.9 if task[6] == 1 else 0.0 \n",
        "    \n",
        "    # original list\n",
        "    # pHF = 0.99 if task[0] == 1 else 0.0\n",
        "    # pVF = 0.99 if task[1] == 1 else 0.0\n",
        "    # rotAng = 359.0 if task[2] == 1 else 0.0\n",
        "    # pPersp = 0.99 if task[3] == 1 else 0.0    \n",
        "    # cropScale = 0.5 if task[4] == 1 else 1.0\n",
        "    # pNoise = 0.99 if task[5] == 1 else 0.0\n",
        "    # satVal = 4.0 if task[6] == 1 else 0.0\n",
        "    # brightVal = 0.5 if task[7] == 1 else 0.0\n",
        "    # contrastVal = 0.9 if task[7] == 1 else 0.0 \n",
        "    # blurSigma = (0.01, 2.0) if task[8] == 1 else 1e-9     \n",
        "\n",
        "    return (pHF, pVF, rotAng, \n",
        "            # pPersp, \n",
        "            cropScale, pNoise, \n",
        "            satVal, brightVal, contrastVal\n",
        "            # blurSigma\n",
        "            )\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkdPMMvRJlp2"
      },
      "source": [
        "\n",
        "def applyAugs(img_batch, current_task):\n",
        "\n",
        "    # pHF, pVF, rotAng, pPersp, cropScale, pNoise, satVal, brightVal, contrastVal, blurSigma = makeAugParams(current_task)\n",
        "    pHF, pVF, rotAng, cropScale, pNoise, satVal, brightVal, contrastVal = makeAugParams(current_task)\n",
        "\n",
        "    transform_list = [transforms.RandomHorizontalFlip(p=pHF),\n",
        "                      transforms.RandomVerticalFlip(p=pVF),\n",
        "                      transforms.RandomRotation(rotAng, fill=0.5),\n",
        "                      # transforms.RandomPerspective(distortion_scale=0.1, p=pPersp, fill=0.5),\n",
        "                      transforms.RandomResizedCrop(256,\n",
        "                                                   scale=(cropScale, 1.0),\n",
        "                                                   ratio=(1.0, 1.0),\n",
        "                                                   interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "                      addGaussianNoise(std=0.1, p=pNoise),\n",
        "                      transforms.ColorJitter(saturation=satVal, hue=0.01),\n",
        "                      transforms.ColorJitter(brightness=brightVal, contrast=contrastVal)\n",
        "                      # transforms.GaussianBlur(9, sigma=blurSigma)\n",
        "                      ]\n",
        "    \n",
        "    for i in range(numAugs):\n",
        "      if current_task[i]==1:\n",
        "        # t0 = time.time()\n",
        "        transform = transform_list[i]\n",
        "        img_batch = transform(img_batch)\n",
        "        # print(i, time.time() - t0)\n",
        "\n",
        "    return img_batch\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TisyS9syQ6n4"
      },
      "source": [
        "\n",
        "# Create full-factorial combination of the augmentations. Each\n",
        "# one will be a \"task.\" Each augmentation will only have 2 levels (on and off).\n",
        "# Hence, there will be 512 tasks if there are 9 augs with 2 levels each.\n",
        "\n",
        "# First, set number of augmentations per task.\n",
        "numAugs = 7\n",
        "augTasks = list(itertools.product([0, 1], repeat=numAugs))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c0gzVp0fgBQ"
      },
      "source": [
        "\n",
        "# select random task (for testing)\n",
        "# in actual implementation we would iterate through the task list\n",
        "current_task = augTasks[random.randint(0, 128)]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQUaJ4DCi_EM"
      },
      "source": [
        "\n",
        "# prepare a minibatch of images\n",
        "batch_size = 256\n",
        "\n",
        "d = data[0:batch_size]\n",
        "d = d / 255.0\n",
        "d = np.moveaxis(d, 3, 1)\n",
        "d = torch.as_tensor(d)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP2QqrUKoYQt",
        "outputId": "b26dd8d4-ce8e-4b07-b575-5706ed820014"
      },
      "source": [
        "\n",
        "# transform minibatch of images\n",
        "t0 = time.time()\n",
        "transformed_batch = applyAugs(d, current_task)\n",
        "print(\"Time to transform batch of size {:d}: {:0f}\".format(len(d), time.time()-t0))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to transform batch of size 256: 4.470423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y65WpAQMogRv"
      },
      "source": [
        "\n",
        "# plot sample of results\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "transformed_batch = transformed_batch.numpy()\n",
        "transformed_batch = np.moveaxis(transformed_batch, 1, 3)\n",
        "\n",
        "fig = plt.figure(figsize=(15., 15.))\n",
        "grid = ImageGrid(fig, 111,  \n",
        "                 nrows_ncols=(4, 4),  \n",
        "                 axes_pad=0.1)\n",
        "\n",
        "for ax, im in zip(grid, transformed_batch[0:16]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "del transformed_batch\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}