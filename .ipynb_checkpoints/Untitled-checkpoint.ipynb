{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow_datasets as tfds\n",
    "import torchvision\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "## All Hyperparams should go here. CGAN, CAEGAN, ICAEGAN\n",
    "img_size = 32 # can use this to mofidy data size to fit this model\n",
    "n_epochs = 10 #50? depends on max_sampels\n",
    "print_stride = 1\n",
    "#n_samples = 8000 #80k, 10k is fine\n",
    "bs = 16 # 64\n",
    "\n",
    "z_dim = 100\n",
    "\n",
    "learning_rate = 0.0002\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize(img_size),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=bs,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=bs,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(next(iter(train_loader))[0].shape)\n",
    "print(next(iter(train_loader))[1].shape)\n",
    "\n",
    "first_samp = next(iter(train_loader))[0][0]\n",
    "print(torch.min(first_samp), torch.max(first_samp))\n",
    "plt.imshow(0.5*(first_samp.permute(1,2,0) + 1))\n",
    "\n",
    "print(next(iter(train_loader))[1][0])\n",
    "\n",
    "\n",
    "\n",
    "#y_train = torch.nn.functional.one_hot(torch.tensor(y_train).to(torch.int64))\n",
    "#print(y_train.shape)\n",
    "#print(y_train)\n",
    "\n",
    "#y_train = torch.squeeze(y_train)\n",
    "#print(y_train.shape)\n",
    "#print(torch.sum(y_train, dim = 0))\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # Condition Up-Embedder:\n",
    "        self.fc1 = nn.Linear(c_dim, img_size**2, bias = False)\n",
    "        # Discriminator:\n",
    "        self.conv1 = nn.Conv2d(4, 128, 4, 2, 1) # (bs, 3 + , img_size, img_size)\n",
    "        self.conv2 = nn.Conv2d(128, 256, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3 = nn.Conv2d(256, 512, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4 = nn.Conv2d(512, 1024, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(1024)\n",
    "        self.conv5 = nn.Conv2d(1024, 1, 2, 1, 0)\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m])\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        c = torch.tanh(self.fc1(c.view(mini_batch, c_dim))).view(mini_batch, 1, img_size, img_size) # Tanh: Since x is in (-1,1), c should probably too\n",
    "        #print(x.shape, c.shape)\n",
    "        x = torch.cat((x, c), dim = 1)\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ## Decoding:\n",
    "        self.deconv1v = nn.ConvTranspose2d(v_dim, 1024, 4, 1, 0, bias = False) # Not sure how this looks\n",
    "        self.deconv1c = nn.ConvTranspose2d(c_dim, 1024, 4, 1, 0, bias = False) # Input: (bs, cdim+v_dim, 1, 1)\n",
    "\n",
    "        self.deconv1_bn = nn.BatchNorm2d(1024)\n",
    "        self.deconv2 = nn.ConvTranspose2d(1024+1024, 512, 4, 2, 1, bias = False)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(512)\n",
    "        self.deconv3 = nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(256)\n",
    "        self.deconv4 = nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(128)\n",
    "        self.deconv5 = nn.ConvTranspose2d(128, 3, 3, 1, 1)\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m])\n",
    "\n",
    "    def forward(self, v, c):\n",
    "        v = self.deconv1_bn(self.deconv1v(v))\n",
    "        c = self.deconv1_bn(self.deconv1c(c))\n",
    "        x = torch.cat((v, c), dim = 1) #stack on channel dim, should be (bs, vdim+cdim, 1, 1). Not sure here\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = torch.tanh(self.deconv5(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def normal_init(m):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        #m.bias.data.zero_()\n",
    "\n",
    "def get_codes(size, hardware = device, hot = True):\n",
    "    if hot == True:\n",
    "        return one_hot_embedding(torch.randint(c_dim, size = (size, 1), device = hardware))\n",
    "\n",
    "    else:\n",
    "        return torch.randint(c_dim, size = (size, 1), device = hardware)\n",
    "\n",
    "def one_hot_embedding(labels):\n",
    "    #y = torch.eye(num_classes)\n",
    "    #return y[labels]\n",
    "    #return torch.nn.functional.one_hot(labels)[:,1:]\n",
    "\n",
    "    labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64), num_classes = c_dim)\n",
    "    return torch.squeeze(labels)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def print_g_sample():\n",
    "    with torch.no_grad():\n",
    "        codes = one_hot_embedding(torch.tensor(list(range(9)), device = device)).view(9,c_dim,1,1).float()\n",
    "        varis = torch.randn((9, v_dim,1,1), device = device) # walk from [0,...,0] to [1,...,1]\n",
    "        generated = .5*(G(varis, codes).cpu() + 1)\n",
    "        for i in range(9):\n",
    "            plt.subplot(330 + 1 + i)\n",
    "            # plot raw pixel data\n",
    "            element = generated[i,:].permute(1,2,0)\n",
    "            plt.imshow(element)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "G.weight_init()\n",
    "D.weight_init()\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "\n",
    "BCE_loss = nn.BCELoss()\n",
    "learning_rate = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "G_optimizer = optim.Adam(G.parameters(),\n",
    "                         lr = learning_rate,\n",
    "                         betas = (beta_1, beta_2))\n",
    "\n",
    "D_optimizer = optim.Adam(D.parameters(),\n",
    "                         lr = learning_rate,\n",
    "                         betas = (beta_1, beta_2))\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "G_loss_tracker, D_loss_tracker = [], []\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "\n",
    "    for X, code in train_loader:\n",
    "        mini_batch = X.size()[0]\n",
    "        X = X.to(device)\n",
    "        code = code.to(device)\n",
    "        code = one_hot_embedding(code).float()\n",
    "\n",
    "\n",
    "        ## Discriminator Training\n",
    "        for param in D.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "\n",
    "        y_real = torch.ones((mini_batch,1,1,1), device = device)*D_real_scale # Sometimes .9, .1\n",
    "        y_fake = torch.ones((mini_batch,1,1,1), device = device)*D_fake_scale # \n",
    "\n",
    "        rand_v = torch.randn((mini_batch, v_dim, 1, 1), device = device)\n",
    "        rand_c = get_codes(mini_batch).view(mini_batch, c_dim, 1, 1).float()\n",
    "\n",
    "        #print(X.shape, code.shape)\n",
    "        D_real_out = D(X, code)\n",
    "        D_real_loss = BCE_loss(D_real_out, y_real)\n",
    "\n",
    "        X_fake = G(rand_v, rand_c)\n",
    "        D_fake_out = D(X_fake, rand_c)\n",
    "        D_fake_loss = BCE_loss(D_fake_out, y_fake)\n",
    "\n",
    "        D_loss = D_real_loss + D_fake_loss\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        ## Generator Training\n",
    "        for param in D.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        rand_v = torch.randn((mini_batch, v_dim, 1, 1), device = device)\n",
    "        rand_c = get_codes(mini_batch).view(mini_batch, c_dim, 1, 1).float()\n",
    "        X_fake = G(rand_v, rand_c)\n",
    "        D_out = D(X_fake, rand_c)\n",
    "        y_targ = torch.ones((mini_batch,1,1,1), device = device) #G gets low loss when D returns X_fake near 1\n",
    "        G_loss = BCE_loss(D_out, y_targ)\n",
    "\n",
    "        ## Loss combination\n",
    "        model_loss = G_loss\n",
    "        model_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        D_losses.append(D_loss.data.item())\n",
    "        G_losses.append(G_loss.data.item())\n",
    "\n",
    "    if epoch % print_stride == 0:\n",
    "        print('Epoch {} - loss_D: {:.3f}, loss_G: {:.3f}'.format((epoch),\n",
    "                                                               torch.mean(torch.FloatTensor(D_losses)),\n",
    "                                                               torch.mean(torch.FloatTensor(G_losses))))\n",
    "\n",
    "        G_loss_tracker.append(torch.mean(torch.FloatTensor(G_losses)))\n",
    "        D_loss_tracker.append(torch.mean(torch.FloatTensor(D_losses)))\n",
    "        print_g_sample()\n",
    "\n",
    "\n",
    "\n",
    "torch.save(G.state_dict(), f'c_gan_cifar_{exp_num}_G.pt')\n",
    "return D, G\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
