{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "data = np.load('data/RESISC45_images_96.npy')\n",
    "labels = np.load('data/RESISC45_classes.npy')\n",
    "\n",
    "test_size = 0.25\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data, labels, test_size = test_size, stratify = labels)\n",
    "\n",
    "\n",
    "np.save('data/RESISC45_images_train.npy', xtrain)\n",
    "np.save('data/RESISC45_labels_train.npy', ytrain)\n",
    "np.save('data/RESISC45_images_test.npy', xtest)\n",
    "np.save('data/RESISC45_labels_test.npy', ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (23625, 96, 96, 3)\n",
      "Testing data shape:  (23625,)\n",
      "Num Classes (45,)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load('data/RESISC45_images_train.npy')\n",
    "train_labels = np.load('data/RESISC45_labels_train.npy')\n",
    "classes = np.load('data/RESISC45_class_names.npy')\n",
    "\n",
    "print('Training data shape: ', train_data.shape)\n",
    "print('Testing data shape: ', train_labels.shape)\n",
    "print('Num Classes', classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "img_size = train_data.shape[2]# can use this to mofidy data size to fit this model (which only takes 256 images)\n",
    "n_epochs = 30 # 25+ needed. just keep raising this number...\n",
    "print_stride = n_epochs // 15\n",
    "bs = 32 # 64\n",
    "\n",
    "z_dim = 250\n",
    "c_dim = classes.shape[0]\n",
    "\n",
    "print(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n",
      "tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n",
      "torch.Size([7875, 96, 96, 3])\n",
      "torch.Size([7875, 3, 96, 96])\n",
      "tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-c44b232db32c>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xtest = torch.tensor(test_data).permute(0,3,1,2)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xval, ytrain, yval = train_test_split(train_data, train_labels, test_size = 0.25)\n",
    "\n",
    "xtrain = torch.tensor(xtrain).permute(0,3,1,2)\n",
    "print(torch.min(xtrain), torch.max(xtrain))\n",
    "\n",
    "trainset = []\n",
    "for i in range(xtrain.shape[0]):\n",
    "    trainset.append((xtrain[i], ytrain[i]))\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=bs,\n",
    "                                          shuffle=False) #BUG: must keep shuffle false - or else it screws up labels, apparently\n",
    "\n",
    "## Validation Data\n",
    "valset = []\n",
    "xval = torch.tensor(xval).permute(0,3,1,2)\n",
    "\n",
    "print(torch.min(xval), torch.max(xval))\n",
    "for i in range(xval.shape[0]):\n",
    "    valset.append((xval[i], yval[i]))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=64, drop_last = True,\n",
    "                                          shuffle=False) #BUG: must keep shuffle false - or else it screws up labels, apparently\n",
    "\n",
    "test_data = np.load('data/RESISC45_images_test.npy')\n",
    "test_labels = np.load('data/RESISC45_labels_test.npy')\n",
    "\n",
    "test_data = torch.tensor(test_data)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "## Testing Data\n",
    "testset = []\n",
    "print(test_data.shape)\n",
    "xtest = torch.tensor(test_data).permute(0,3,1,2)\n",
    "print(xtest.shape)\n",
    "\n",
    "print(torch.min(test_data), torch.max(test_data))\n",
    "for i in range(test_data.shape[0]):\n",
    "    testset.append((test_data[i], test_labels[i]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, drop_last = True,\n",
    "                                          shuffle=False) #BUG: must keep shuffle false - or else it screws up labels, apparently\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "class Conv_Pred(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Conv_Pred, self).__init__()\n",
    "        ## Encoding: Unconditional samples\n",
    "        self.conv1 = nn.Conv2d(3, 32, 4, 2, 1) # Input: (bs, 3, img_size, img_size)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 2, 1, bias = False)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 4, 2, 1, bias = False)\n",
    "        self.conv3_bn = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4, 2, 1, bias = False)\n",
    "        self.conv4_bn = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(256, 512, 4, 2, 1, bias = False)\n",
    "        self.conv5_bn = nn.BatchNorm2d(512)\n",
    "        self.conv6 = nn.Conv2d(512, 1024, 4, 2, 1, bias = False)\n",
    "        self.conv6_bn = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        #self.conv7 = nn.Conv2d(2048, z_dim, 4, 2, 0) # Output: (bs, c_dim, 1, 1)\n",
    "        self.fce = nn.Linear(1024, 45)\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode data x to 2 spaces: condition space and variance-space\n",
    "        x = F.relu(self.conv1(x), 0.2)\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "        x = F.relu(self.conv4_bn(self.conv4(x)))\n",
    "        x = F.relu(self.conv5_bn(self.conv5(x)))\n",
    "        x = F.relu(self.conv6_bn(self.conv6(x)))\n",
    "\n",
    "        z = nn.Softmax(dim=1)(self.fce(x.squeeze()))\n",
    "\n",
    "        return z\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def normal_init(m):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        #m.bias.data.zero_()\n",
    "\n",
    "def one_hot_embedding(labels):\n",
    "    labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64), num_classes = c_dim)\n",
    "    return torch.squeeze(labels)\n",
    "\n",
    "def accuracy(output, target, topk=(5,)):\n",
    "    #https://gist.github.com/weiaicunzai/2a5ae6eac6712c70bde0630f3e76b77b\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = Conv_Pred()\n",
    "CNN.weight_init()\n",
    "CNN.to(device)\n",
    "\n",
    "bce_loss = nn.BCELoss()\n",
    "mse_loss = nn.MSELoss()\n",
    "mae_loss = nn.L1Loss()\n",
    "learning_rate = 0.0008\n",
    "\n",
    "augmentations = True\n",
    "\n",
    "class LightningRESISCClassifier(pl.LightningModule):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = 1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def BCELoss(self, inp, targ):\n",
    "        return bce_loss(inp, targ)\n",
    "    \n",
    "    \n",
    "augmentation_list = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.3),\n",
    "        transforms.RandomVerticalFlip(p=0.3),\n",
    "        transforms.RandomPerspective(distortion_scale=0.1, p=0.3, fill=0.5),\n",
    "        transforms.RandomAffine(180)\n",
    "        #transforms.ColorJitter(saturation=0.2, hue=0.01),\n",
    "        #transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    " \n",
    "  # TRAINING LOOP\n",
    "    for train_batch in mnist_train:\n",
    "        x, y = train_batch                       # training_step\n",
    "\n",
    "        logits = pytorch_model(x)                # training_step\n",
    "        loss = cross_entropy_loss(logits, y)     # training_step\n",
    "        print('train loss: ', loss.item())       # training_step\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "      # VALIDATION LOOP\n",
    "    with torch.no_grad():\n",
    "        val_loss = []\n",
    "        for val_batch in mnist_val:\n",
    "            x, y = val_batch                                      # validation_step\n",
    "            logits = pytorch_model(x)                             # validation_step\n",
    "            val_loss.append(cross_entropy_loss(logits, y).item())\n",
    "\n",
    "        val_loss = torch.mean(torch.tensor(val_loss))           # validation_epoch_end\n",
    "        print('val_loss: ', val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-e0e78e563d29>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64), num_classes = c_dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - loss_CNN: 0.065\n",
      "Validation Accuracy:  0.22995923459529877\n",
      "Epoch 4 - loss_CNN: 0.047\n",
      "Validation Accuracy:  0.24575407803058624\n",
      "Epoch 6 - loss_CNN: 0.038\n",
      "Validation Accuracy:  0.22860054671764374\n",
      "Epoch 8 - loss_CNN: 0.032\n",
      "Validation Accuracy:  0.2501698434352875\n",
      "Epoch 10 - loss_CNN: 0.027\n",
      "Validation Accuracy:  0.28651493787765503\n",
      "Epoch 12 - loss_CNN: 0.024\n",
      "Validation Accuracy:  0.24898098409175873\n",
      "Epoch 14 - loss_CNN: 0.021\n",
      "Validation Accuracy:  0.29653531312942505\n",
      "Epoch 16 - loss_CNN: 0.018\n",
      "Validation Accuracy:  0.31368884444236755\n",
      "Epoch 18 - loss_CNN: 0.016\n",
      "Validation Accuracy:  0.2484714686870575\n",
      "Epoch 20 - loss_CNN: 0.014\n",
      "Validation Accuracy:  0.23811140656471252\n",
      "Epoch 22 - loss_CNN: 0.012\n",
      "Validation Accuracy:  0.2890625\n",
      "Epoch 24 - loss_CNN: 0.010\n",
      "Validation Accuracy:  0.2992527186870575\n",
      "Epoch 26 - loss_CNN: 0.009\n",
      "Validation Accuracy:  0.3062160313129425\n",
      "Epoch 28 - loss_CNN: 0.008\n",
      "Validation Accuracy:  0.346807062625885\n",
      "Epoch 30 - loss_CNN: 0.006\n",
      "Validation Accuracy:  0.3165760934352875\n"
     ]
    }
   ],
   "source": [
    "CNN_loss_tracker = []\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    CNN_losses = []\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        #print(torch.min(X), torch.max(X))\n",
    "        mini_batch = X.size()[0]\n",
    "        X = X.to(device).float()\n",
    "        X = 2.0*(X/255 - 0.5)\n",
    "        y = one_hot_embedding(y.to(device)).float()\n",
    "        \n",
    "        if augmentations == True:\n",
    "            X = augmentation_list(X)\n",
    "\n",
    "        ## CNN Training\n",
    "        for param in CNN.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        yhat = CNN(X)\n",
    "        pred_loss = bce_loss(yhat, y)\n",
    "        \n",
    "        model_loss = pred_loss\n",
    "\n",
    "        model_loss.backward()\n",
    "        CNN_optimizer.step()\n",
    "\n",
    "        CNN_losses.append(pred_loss.data.item())\n",
    "        \n",
    "\n",
    "    if epoch % print_stride == 0:\n",
    "        print('Epoch {} - loss_CNN: {:.3f}'.format((epoch), torch.mean(torch.FloatTensor(CNN_losses))))\n",
    "\n",
    "        CNN_loss_tracker.append(torch.mean(torch.FloatTensor(CNN_losses)))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            topks = []\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).float(), y.to(device).float()\n",
    "                #print(x, y)\n",
    "                yhat = CNN(x)\n",
    "                \n",
    "                yhat = torch.max(yhat, dim = 1)[1]\n",
    "                #print(yhat.shape)\n",
    "                \n",
    "                correct = torch.sum(yhat == y)\n",
    "                size = x.shape[0]\n",
    "                \n",
    "                topks.append((correct/size).data.item())\n",
    "                \n",
    "            print('Validation Accuracy: ', torch.mean(torch.FloatTensor(topks)).data.item())\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = next(iter(val_loader))\n",
    "x = xy[0].to(device).float()\n",
    "y = xy[1]\n",
    "\n",
    "yhat = CNN(x)\n",
    "print(yhat.shape)\n",
    "res = torch.topk(yhat, 3, dim = 1)\n",
    "print(res[1].shape)\n",
    "\n",
    "\n",
    "\n",
    "accuracy(yhat.to(device), y.to(device), topk=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(CNN_loss_tracker)\n",
    "torch.save(CNN.state_dict(), f'aug_{augmentations}_epo_{n_epochs}_tsize_{test_size}_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yhat)\n",
    "torch.mean(torch.FloatTensor(topks)).data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Embed Train set points:\n",
    "embedded_points = []\n",
    "labels = []\n",
    "\n",
    "AE = AE.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,y in train_loader:\n",
    "        #if x.shape[0] < bs:\n",
    "        #    break\n",
    "        x = 2*((x / 255) - 0.5)\n",
    "        x = AE.encode(x.to(device)).squeeze()\n",
    "        if x.shape[0] == 54:\n",
    "            break\n",
    "        #print(x.shape)\n",
    "        embedded_points.append(x)\n",
    "        labels.append(y)\n",
    "        \n",
    "#print(len(embedded_points))\n",
    "#print(embedded_points[0].shape)\n",
    "#print(embedded_points[-1].shape)\n",
    "embedded_points = embedded_points[:-1] #skip last bad shape\n",
    "labels = labels[:-1]\n",
    "train_embedded = torch.cat(embedded_points, dim=0)\n",
    "train_y = torch.cat(labels, dim = 0)\n",
    "print('train set shape:')\n",
    "print(train_embedded.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "# Embed Validation set points:\n",
    "embedded_points = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,y in val_loader:\n",
    "        x = 2*((x / 255) - 0.5)\n",
    "        \n",
    "        x = AE.encode(x.to(device))\n",
    "        #print(x.shape)\n",
    "        embedded_points.append(x)\n",
    "        labels.append(y)\n",
    "        \n",
    "val_embedded = torch.stack(embedded_points).squeeze()\n",
    "val_y = torch.stack(labels).squeeze()\n",
    "print('validation set shape: ', val_embedded.shape)\n",
    "print(val_y.shape)\n",
    "\n",
    "# Embed test set points:\n",
    "embedded_points = []\n",
    "labels = []\n",
    "\n",
    "print(next(iter(test_loader))[0].shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,y in test_loader:\n",
    "        x = x.permute(0,3,1,2)\n",
    "        \n",
    "        x = 2*((x / 255) - 0.5)\n",
    "        \n",
    "        x = AE.encode(x.to(device))\n",
    "        #print(x.shape)\n",
    "        embedded_points.append(x)\n",
    "        labels.append(y)\n",
    "        \n",
    "test_embedded = torch.stack(embedded_points).squeeze()\n",
    "test_y = torch.stack(labels).squeeze()\n",
    "print('test set shape:')\n",
    "print(test_embedded.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch using training set on validation set\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "from sklearn import tree, ensemble, neighbors, neural_network\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "n_samples = 1000\n",
    "print('==============================')\n",
    "\n",
    "train_data = train_embedded.cpu()[0:n_samples]\n",
    "val_data = val_embedded.cpu()[0:n_samples]\n",
    "\n",
    "train_y = train_y[0:n_samples]\n",
    "val_y = val_y[0:n_samples]\n",
    "\n",
    "print('train_data.shape', train_data.shape)\n",
    "\n",
    "print('test_data shape', val_data.shape)\n",
    "\n",
    "print(train_y.shape, val_y.shape)\n",
    "\n",
    "if True:\n",
    "    ## RandomForestClassifier\n",
    "    model = sklearn.ensemble.RandomForestClassifier()\n",
    "    parameters = {'n_estimators':(range(2,503, 50)), \n",
    "                  'max_depth':(range(3,10,1)), \n",
    "                  'min_samples_leaf':(range(2,8,2))}\n",
    "    clf = GridSearchCV(model, parameters)\n",
    "    clf.fit(train_data, train_y)\n",
    "    print('RFC: ', clf.best_params_)\n",
    "    best = clf.best_params_\n",
    "    Tmodel = sklearn.ensemble.RandomForestClassifier(n_estimators = best['n_estimators'],\n",
    "                                                    max_depth = best['max_depth'],\n",
    "                                                    min_samples_leaf = best['min_samples_leaf'])\n",
    "\n",
    "    Tmodel.fit(train_data, train_y)\n",
    "    y_pred = Tmodel.predict(val_data)\n",
    "\n",
    "if False:\n",
    "    ## K Neighbors Regressor\n",
    "    model = sklearn.neighbors.KNeighborsClassifier(algorithm = 'auto')\n",
    "    parameters = {'n_neighbors':(range(2,12)), \n",
    "                  'weights':('uniform', 'distance'), \n",
    "                  'leaf_size':(range(2,63,10))}\n",
    "    clf = GridSearchCV(model, parameters)\n",
    "    clf.fit(train_data, train_y)\n",
    "    print('K-Neighbors Regressor: ', clf.best_params_)\n",
    "    best = clf.best_params_\n",
    "    Tmodel = sklearn.neighbors.KNeighborsClassifier(algorithm = 'auto',\n",
    "                                                    n_neighbors = best['n_neighbors'],\n",
    "                                                    weights = best['weights'],\n",
    "                                                    leaf_size = best['leaf_size'])\n",
    "\n",
    "    Tmodel.fit(train_data, train_y)\n",
    "    y_pred = Tmodel.predict(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent_predictor import fit_optim_predictor\n",
    "clf, final = fit_optim_predictor(train_embedded, train_y, val_embedded, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = sklearn.metrics.accuracy_score(val_y, y_pred)\n",
    "#f1_score = sklearn.metrics.f1_score(val_y, y_pred, average = 'samples')\n",
    "top_5 = sklearn.metrics.classification_report(val_y, y_pred)\n",
    "#pscore = sklearn.metrics.precision_score(val_y, y_pred)\n",
    "print('Val Acc: ', val_acc)\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
