{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EbTkUprLIz9G"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torchsummary\n",
    "import copy\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3P-Hlw2OJeUc",
    "outputId": "9a7761f6-0f6f-4826-ec88-c9cedfe129d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# Get sample image from Google Drive and load it for debugging. Will need to\n",
    "# modify code to deal with mini-batch of RGB image.\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m63ebfAVxMQY",
    "outputId": "016827d3-d0e4-458d-c98c-20fa022b54ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/MyDrive/Adam/Courses/WPI/DS 541 Deep Learning/Project\n",
      "'=1.8.0'\n",
      " airport_001.jpg\n",
      "\u001b[0m\u001b[01;34m'Reference papers'\u001b[0m/\n",
      "'Remote Sensing Image Scene Classification Proposal.gdoc'\n",
      " RESISC45_classes.npy\n",
      " RESISC45_class_names.npy\n",
      " RESISC45_extract_image_files.py\n",
      " RESISC45_images.npy\n"
     ]
    }
   ],
   "source": [
    "# In Google Drive, create a shortcut link of the shared Project folder so that it appears in your root Google Drive directory\n",
    "# i.e., Right Click Project folder: \"Add Shortcut to Drive\"\n",
    "\n",
    "%cd '/gdrive/MyDrive/Project/'\n",
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AlXorlebOvZ",
    "outputId": "fbf8859b-1776-46df-8c0e-cbe2f9dbf50c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (31500, 256, 256, 3)\n",
      "Testing data shape:  (31500,)\n",
      "Num Classes (45,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('RESISC45_images.npy')\n",
    "labels = np.load('RESISC45_classes.npy')\n",
    "classes = np.load('RESISC45_class_names.npy')\n",
    "\n",
    "print('Training data shape: ', data.shape)\n",
    "print('Testing data shape: ', labels.shape)\n",
    "print('Num Classes', classes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DhwY3ieSJkqO"
   },
   "outputs": [],
   "source": [
    "\n",
    "class addGaussianNoise(object):\n",
    "    # Transform to add gaussian noise since PyTorch did not have one (that I know of).\n",
    "    def __init__(self, mean=0.0, std=1.0, p=0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.p = p\n",
    "      \n",
    "    def __call__(self, img):\n",
    "        if torch.rand(1).item() < self.p:\n",
    "            return img + torch.randn(img.size()) * self.std + self.mean\n",
    "        return img\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1}, p={2})'.format(self.mean, self.std, self.p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nkdPMMvRJlp2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def composeAugs(params):\n",
    "    # Function to compose the augmentations, the order of which will be fixed.\n",
    "    # Some of these parameters are best guess and can be changed if we need to.\n",
    "    # For example, hue is set to have very very minor change because it can \n",
    "    # create false colors (green grass can become magenta). If the team decides\n",
    "    # that false colors are acceptable, we can change the hue parameter.\n",
    "    \n",
    "    # Scripting the transformations will not work here due to the inclusion of\n",
    "    # addGaussianNoise transform. Use transform composition instead.\n",
    "\n",
    "\n",
    "    pHF, pVF, rotAng, pPersp, cropScale, pNoise, satVal, brightVal, contrastVal, blurSigma = params\n",
    "\n",
    "    imXforms = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=pHF),\n",
    "        transforms.RandomVerticalFlip(p=pVF),\n",
    "        transforms.RandomRotation(rotAng, fill=0.5),\n",
    "        transforms.RandomPerspective(distortion_scale=0.1, p=pPersp, fill=0.5),\n",
    "        transforms.RandomResizedCrop(256,\n",
    "                                    scale=(cropScale, 1.0),\n",
    "                                    ratio=(1.0, 1.0),\n",
    "                                    interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        addGaussianNoise(std=0.1, p=pNoise),\n",
    "        transforms.ColorJitter(saturation=satVal, hue=0.01),\n",
    "        transforms.ColorJitter(brightness=brightVal, contrast=contrastVal),\n",
    "        transforms.GaussianBlur(9, sigma=blurSigma)\n",
    "        ])\n",
    "        \n",
    "    return imXforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lb4gUZzoU_fr"
   },
   "outputs": [],
   "source": [
    "\n",
    "# set augmentation parameters for input task\n",
    "def makeAugParams(task):\n",
    "    pHF = 0.99 if task[0] == 1 else 0.0\n",
    "    pVF = 0.99 if task[1] == 1 else 0.0\n",
    "    rotAng = 359.0 if task[2] == 1 else 0.0\n",
    "    pPersp = 0.99 if task[3] == 1 else 0.0\n",
    "    cropScale = 0.5 if task[4] == 1 else 1.0\n",
    "    pNoise = 0.99 if task[5] == 1 else 0.0\n",
    "    satVal = 4.0 if task[6] == 1 else 0.0\n",
    "    brightVal = 0.5 if task[7] == 1 else 0.0\n",
    "    contrastVal = 0.9 if task[7] == 1 else 0.0\n",
    "    blurSigma = (0.01, 2.0) if task[8] == 1 else 1e-9\n",
    "\n",
    "    return (pHF, pVF, rotAng, pPersp, cropScale, pNoise, \n",
    "            satVal, brightVal, contrastVal, blurSigma)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TisyS9syQ6n4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create full-factorial combination of the augmentations. Each\n",
    "# one will be a \"task.\" Each augmentation will only have 2 levels (on and off).\n",
    "# Hence, there will be 512 tasks if there are 9 augs with 2 levels each.\n",
    "\n",
    "# First, set number of augmentations per task.\n",
    "numAugs = 9\n",
    "augTasks = list(itertools.product([0, 1], repeat=numAugs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4c0gzVp0fgBQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# select random task (for testing)\n",
    "# in actual implementation we would iterate through the task list\n",
    "current_task = augTasks[random.randint(0,512)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "n3MOG1bVuqWE"
   },
   "outputs": [],
   "source": [
    "\n",
    "# define augmentation transforms\n",
    "aug_params = makeAugParams(current_task)\n",
    "image_transforms = composeAugs(aug_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jQUaJ4DCi_EM"
   },
   "outputs": [],
   "source": [
    "\n",
    "# prepare a minibatch of images\n",
    "batch_size = 256\n",
    "\n",
    "d = data[0:batch_size]\n",
    "d = d / 255.0\n",
    "d = np.moveaxis(d, 3, 1)\n",
    "d = torch.as_tensor(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EP2QqrUKoYQt",
    "outputId": "00b1ea32-d318-4c10-e660-0449ae5bb6dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to transform batch of size 256: 18.569443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# transform minibatch of images\n",
    "t0 = time.time()\n",
    "transformed_batch = image_transforms(d)\n",
    "print(\"Time to transform batch of size {:d}: {:0f}\".format(len(d), time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y65WpAQMogRv"
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot sample of results\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "transformed_batch = transformed_batch.numpy()\n",
    "transformed_batch = np.moveaxis(transformed_batch, 1, 3)\n",
    "\n",
    "fig = plt.figure(figsize=(15., 15.))\n",
    "grid = ImageGrid(fig, 111,  \n",
    "                 nrows_ncols=(4, 4),  \n",
    "                 axes_pad=0.1)\n",
    "\n",
    "for ax, im in zip(grid, transformed_batch[0:16]):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del transformed_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEhe_6rxJUOs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Scott Augmentations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
