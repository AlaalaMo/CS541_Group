{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchmeta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5c8e0da1931a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOmniglot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mClassSplitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCompose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchmeta'"
     ]
    }
   ],
   "source": [
    "# This is a sample Python script.\n",
    "\n",
    "# Press Shift+F10 to execute it or replace it with your code.\n",
    "# Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "import torchvision\n",
    "\n",
    "from torchmeta.datasets import Omniglot\n",
    "from torchmeta.transforms import Categorical, ClassSplitter, Rotation\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchmeta.datasets.helpers import omniglot\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "from torchmeta.utils.gradient_based import gradient_update_parameters\n",
    "\n",
    "from model import ConvolutionalNeuralNetwork\n",
    "from utils import get_accuracy\n",
    "from torchmeta.modules import (MetaModule, MetaSequential, MetaConv2d,\n",
    "                               MetaBatchNorm2d, MetaLinear)\n",
    "\n",
    "\n",
    "# def conv3x3(in_channels, out_channels, **kwargs):\n",
    "#     return MetaSequential(\n",
    "#         MetaConv2d(in_channels, out_channels, kernel_size=2, padding=1, **kwargs),\n",
    "#         MetaBatchNorm2d(out_channels, momentum=1., track_running_stats=False),\n",
    "#         nn.ReLU(),\n",
    "#         nn.MaxPool2d(2)\n",
    "#     )\n",
    "\n",
    "class ConvolutionalNeuralNetwork(MetaModule):\n",
    "    def __init__(self, in_channels, out_features,num_classes, hidden_size=2):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_features = out_features\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "\n",
    "        self.conv = MetaSequential(\n",
    "            MetaConv2d(in_channels,hidden_size**5,kernel_size=4,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            MetaConv2d(hidden_size**5,hidden_size**6,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "            MetaBatchNorm2d(hidden_size**6),\n",
    "            nn.ReLU(),\n",
    "            MetaConv2d(hidden_size ** 6, hidden_size ** 7, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            MetaBatchNorm2d(hidden_size**7),\n",
    "            nn.ReLU(),\n",
    "            MetaConv2d(hidden_size ** 7, hidden_size ** 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            MetaBatchNorm2d(hidden_size ** 8),\n",
    "            nn.ReLU(),\n",
    "            MetaConv2d(hidden_size ** 8, hidden_size ** 9, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            MetaBatchNorm2d(hidden_size ** 9),\n",
    "            nn.ReLU(),\n",
    "            MetaConv2d(hidden_size ** 9, hidden_size ** 10, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            MetaBatchNorm2d(hidden_size ** 10),\n",
    "            nn.Relu()\n",
    "        )\n",
    "        self.classifier = MetaLinear(hidden_size**10, num_classes)\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m])\n",
    "    def forward(self, inputs, params=None):\n",
    "        features = self.features(inputs, params=self.get_subdict(params, 'features')) ## can do inner loop and just upate cnn or ae\n",
    "        features = features.view((features.size(0), -1))\n",
    "        logits = self.classifier(features, params=self.get_subdict(params, 'classifier'))\n",
    "        return logits\n",
    "    \n",
    "def print_hi(name):\n",
    "    # Use a breakpoint in the code line below to debug your script.\n",
    "    print(f'Hi, {name}')  # Press Ctrl+F8 to toggle the breakpoint.\n",
    "    \n",
    "def train(model,dataloader,num_batch):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device=device)\n",
    "    model.train()\n",
    "    meta_optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    acc= []\n",
    "    with tqdm(dataloader, total=num_batch) as pbar:\n",
    "            for batch_idx, batch in enumerate(pbar):\n",
    "                model.zero_grad()\n",
    "\n",
    "\n",
    "                train_inputs, train_targets = batch['train']\n",
    "                train_inputs = train_inputs.to(device=device)\n",
    "                train_targets = train_targets.to(device=device)\n",
    "\n",
    "                test_inputs, test_targets = batch['test']\n",
    "                test_inputs = test_inputs.to(device=device)\n",
    "                test_targets = test_targets.to(device=device)\n",
    "\n",
    "                outer_loss = torch.tensor(0., device=device)\n",
    "                accuracy = torch.tensor(0., device=device)\n",
    "                for task_idx, (train_input, train_target, test_input,\n",
    "                        test_target) in enumerate(zip(train_inputs, train_targets,\n",
    "                        test_inputs, test_targets)):\n",
    "                    train_logit = model(train_input)\n",
    "                    inner_loss = F.cross_entropy(train_logit, train_target)\n",
    "\n",
    "                    model.zero_grad()\n",
    "                    params = gradient_update_parameters(model,\n",
    "                                                        inner_loss,\n",
    "                                                        step_size=.005,\n",
    "                                                        first_order=True)\n",
    "\n",
    "                    test_logit = model(test_input, params=params)\n",
    "                    outer_loss += F.cross_entropy(test_logit, test_target)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        accuracy += get_accuracy(test_logit, test_target)\n",
    "\n",
    "                outer_loss.div_(16)\n",
    "                accuracy.div_(16)\n",
    "\n",
    "                outer_loss.backward()\n",
    "                meta_optimizer.step()\n",
    "                acc.append(accuracy.to(\"cpu\"))\n",
    "                # plt.clf()\n",
    "                # plt.plot(np.asarray(acc))\n",
    "                # plt.ylabel('acc')\n",
    "                # plt.show()\n",
    "                pbar.set_postfix(accuracy='{0:.4f}'.format(accuracy.item()))\n",
    "                if batch_idx >= num_batch:\n",
    "                    break\n",
    "    return acc\n",
    "def get_data():\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "    data = np.load('data/RESISC45_images_96.npy')/255\n",
    "    labels = np.load('data/RESISC45_classes.npy')\n",
    "\n",
    "    test_size = 0.25\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(data, labels, test_size=test_size, stratify=labels)\n",
    "\n",
    "    np.save('data/RESISC45_images_train.npy', xtrain)\n",
    "    np.save('data/RESISC45_labels_train.npy', ytrain)\n",
    "    np.save('data/RESISC45_images_test.npy', xtest)\n",
    "    np.save('data/RESISC45_labels_test.npy', ytest)\n",
    "    train_data = np.load('data/RESISC45_images_train.npy')\n",
    "    train_labels = np.load('data/RESISC45_labels_train.npy')\n",
    "    classes = np.load('data/RESISC45_class_names.npy')\n",
    "    img_size = train_data.shape[2]  # can use this to mofidy data size to fit this model (which only takes 256 images)\n",
    "    bs = 32  # 64\n",
    "    c_dim = classes.shape[0]\n",
    "    xtrain, xval, ytrain, yval = train_test_split(train_data, train_labels, test_size=0.25)\n",
    "\n",
    "    xtrain = torch.tensor(xtrain).permute(0, 3, 1, 2)\n",
    "    print(torch.min(xtrain), torch.max(xtrain))\n",
    "\n",
    "    trainset = []\n",
    "    for i in range(xtrain.shape[0]):\n",
    "        trainset.append((xtrain[i], ytrain[i]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=bs,\n",
    "                                               shuffle=False)  # BUG: must keep shuffle false - or else it screws up labels, apparently\n",
    "\n",
    "    ## Validation Data\n",
    "    valset = []\n",
    "    xval = torch.tensor(xval).permute(0, 3, 1, 2)\n",
    "\n",
    "    print(torch.min(xval), torch.max(xval))\n",
    "    for i in range(xval.shape[0]):\n",
    "        valset.append((xval[i], yval[i]))\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=64, drop_last=True,\n",
    "                                             shuffle=False)  # BUG: must keep shuffle false - or else it screws up labels, apparently\n",
    "\n",
    "    test_data = np.load('data/RESISC45_images_test.npy')\n",
    "    test_labels = np.load('data/RESISC45_labels_test.npy')\n",
    "\n",
    "    test_data = torch.tensor(test_data)\n",
    "    test_labels = torch.tensor(test_labels)\n",
    "    ## Testing Data\n",
    "    testset = []\n",
    "    print(test_data.shape)\n",
    "    xtest = torch.tensor(test_data).permute(0, 3, 1, 2)\n",
    "    print(xtest.shape)\n",
    "\n",
    "    print(torch.min(test_data), torch.max(test_data))\n",
    "    for i in range(test_data.shape[0]):\n",
    "        testset.append((test_data[i], test_labels[i]))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=64, drop_last=True,\n",
    "                                              shuffle=False) # BUG: must keep shuffle false - or else it screws up labels, apparently\n",
    "    Params= {img_size: \"Img_size\", bs: \"bs\", c_dim: \"c_dim\",}\n",
    "\n",
    "    return train_loader,val_loader,test_loader, Params\n",
    "\n",
    "\n",
    "def normal_init(m):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        # m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def one_hot_embedding(labels):\n",
    "    labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64), num_classes=c_dim)\n",
    "    return torch.squeeze(labels)\n",
    "\n",
    "\n",
    "def top_k_acc(inp, targ, k):\n",
    "    # print(inp.shape)\n",
    "    tops = torch.topk(inp, k=k, dim=1)\n",
    "\n",
    "    i = 0\n",
    "    corrects = 0\n",
    "    for row in tops:\n",
    "        for element in row:\n",
    "            if element == targ[i]:\n",
    "                corrects += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return corrects / inp.shape[0]\n",
    "\n",
    "\n",
    "def accuracy_topk(output, target, topk=(3,)):\n",
    "    # https://forums.fast.ai/t/return-top-k-accuracy/27658\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res[0]\n",
    "\n",
    "\n",
    "# Press the green button in the gutter to run the script.\n",
    "if __name__ == '__main__':\n",
    "    print_hi('PyCharm')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dataset = Omniglot(\"data\",\n",
    "                       # Number of ways\n",
    "                       num_classes_per_task=5,\n",
    "                       # Resize the images to 28x28 and converts them to PyTorch tensors (from Torchvision)\n",
    "                       transform=Compose([Resize(28), ToTensor()]),\n",
    "                       # Transform the labels to integers (e.g. (\"Glagolitic/character01\", \"Sanskrit/character14\", ...) to (0, 1, ...))\n",
    "                       target_transform=Categorical(num_classes=5),\n",
    "                       # Creates new virtual classes with rotated versions of the images (from Santoro et al., 2016)\n",
    "                       class_augmentations=[Rotation([90, 180, 270])],\n",
    "                       meta_train=True,\n",
    "                       download=True)\n",
    "    # split the data into train and test\n",
    "    dataset = ClassSplitter(dataset, shuffle=True, num_train_per_class=5, num_test_per_class=15)\n",
    "    # creating batches from dataset\n",
    "    dataloader = BatchMetaDataLoader(dataset, batch_size=16, num_workers=1)# (16, 75)\n",
    "    # import the required libraries and Meta modules from torchmeta\n",
    "    import torch.nn as nn\n",
    "    from torchmeta.modules import (MetaModule, MetaSequential,\n",
    "                                   MetaConv2d, MetaLinear)\n",
    "\n",
    "    model = ConvolutionalNeuralNetwork(1,\n",
    "                                       5,##num ways\n",
    "                                       hidden_size=64)\n",
    "\n",
    "\n",
    "    acccc = train(model,dataloader,1000)\n",
    "    plt.plot(np.asarray(acccc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
