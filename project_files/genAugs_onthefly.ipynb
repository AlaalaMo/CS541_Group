{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "EbTkUprLIz9G"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torchsummary\n",
    "import copy\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3P-Hlw2OJeUc",
    "outputId": "2a8b1e4f-a551-4d2a-a796-1bed51728785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "# Colab specific data loading\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m63ebfAVxMQY",
    "outputId": "bf43875c-86d4-4a33-a863-116dc28ea25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/.shortcut-targets-by-id/1ONXXjIHVMg4MHpAdUIdbB4Fr9W33JPYU/Project\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In Google Drive, create a shortcut link of the shared Project folder so that it appears in your root Google Drive directory\n",
    "# i.e., Right Click Project folder: \"Add Shortcut to Drive\"\n",
    "\n",
    "%cd '/gdrive/MyDrive/Project/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1ATrS7kRFbVg"
   },
   "outputs": [],
   "source": [
    "# # Data should be in a dir named 'data/'\n",
    "data = np.load('data/RESISC45_images.npy')\n",
    "labels = np.load('data/RESISC45_classes.npy')\n",
    "classes = np.load('data/RESISC45_class_names.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AlXorlebOvZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Training data shape: ', data.shape)\n",
    "print('Testing data shape: ', labels.shape)\n",
    "print('Num Classes', classes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DhwY3ieSJkqO"
   },
   "outputs": [],
   "source": [
    "\n",
    "class addGaussianNoise(object):\n",
    "    # Transform to add gaussian noise since PyTorch did not have one (that I know of).\n",
    "    def __init__(self, mean=0.0, std=1.0, p=0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.p = p\n",
    "      \n",
    "    def __call__(self, img):\n",
    "        if torch.rand(1).item() < self.p:\n",
    "            return img + torch.randn(img.size()) * self.std + self.mean\n",
    "        return img\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1}, p={2})'.format(self.mean, self.std, self.p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "nkdPMMvRJlp2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def applyAugs(img_batch, current_task):\n",
    "    # conduct transform operations for task and return transformed batch of images\n",
    "\n",
    "    transform_list = [transforms.RandomHorizontalFlip(p=0.99),\n",
    "                      transforms.RandomVerticalFlip(p=0.99),\n",
    "                      transforms.RandomRotation(359.0, fill=0.5),\n",
    "                      transforms.RandomPerspective(distortion_scale=0.1, p=0.99, fill=0.5),\n",
    "                      transforms.RandomResizedCrop(256,\n",
    "                                                   scale=(0.5, 1.0),\n",
    "                                                   ratio=(1.0, 1.0),\n",
    "                                                   interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "                      addGaussianNoise(std=0.1, p=0.99),\n",
    "                      # transforms.ColorJitter(saturation=4.0, hue=0.01),\n",
    "                      transforms.ColorJitter(brightness=0.5, contrast=0.9)\n",
    "                      # ,transforms.GaussianBlur(9, sigma=(0.01, 2.0))\n",
    "                      ]\n",
    "    \n",
    "    task_transforms = [transform_list[i] for i,x in enumerate(current_task) if x==1]\n",
    "\n",
    "    transform = torchvision.transforms.Compose(task_transforms)\n",
    "    img_batch = transform(img_batch)\n",
    "\n",
    "    return img_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TisyS9syQ6n4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create full-factorial combination of the augmentations. \n",
    "numAugs = 7\n",
    "augTasks = list(itertools.product([0, 1], repeat=numAugs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "jQUaJ4DCi_EM"
   },
   "outputs": [],
   "source": [
    "\n",
    "# prepare a minibatch of images\n",
    "batch_size = 256\n",
    "\n",
    "d = data[0:batch_size]\n",
    "d = d / 255.0\n",
    "d = np.moveaxis(d, 3, 1)\n",
    "d = torch.as_tensor(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4c0gzVp0fgBQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# select random task (for testing)\n",
    "# in actual implementation we would iterate through the task list\n",
    "current_task = augTasks[random.randint(0, 2**numAugs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0tc4Yx4hvIM"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # check timing \n",
    "\n",
    "# # transform minibatch of images\n",
    "# t0 = time.time()\n",
    "# transformed_batch = applyAugs(d, current_task)\n",
    "# t1 = time.time()\n",
    "# print(\"Time to transform batch of size {:d}: {:0f}\".format(len(d), t1-t0))\n",
    "\n",
    "# print(\"estimated total time for all images all tasks: {:.1f} hours\".format((31500/batch_size * (t1-t0)) * (2**numAugs)/60/60/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EP2QqrUKoYQt"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # check timings for individual transforms\n",
    "\n",
    "# for i in range(0, numAugs):\n",
    "#   current_task = [0] * numAugs\n",
    "#   current_task[i] = 1\n",
    "#   t0 = time.time()\n",
    "#   transformed_batch = applyAugs(d, current_task)\n",
    "#   print(\"Aug:\", i, \"{:0f}\".format(time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUBfDGO1szuj"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # transform all images\n",
    "\n",
    "# # test with all augs on\n",
    "# current_task = [1] * numAugs\n",
    "\n",
    "# t0 = time.time()\n",
    "# for i in range(0, data.shape[0], batch_size):\n",
    "#   print(i, time.time() - t0)\n",
    "\n",
    "#   d = data[i:i+batch_size]\n",
    "#   d = d / 255.0\n",
    "#   d = np.moveaxis(d, 3, 1)\n",
    "#   d = torch.as_tensor(d)\n",
    "\n",
    "#   transformed_batch = applyAugs(d, current_task)\n",
    "\n",
    "# print(\"Time to transform entire dataset {:d}: {:0f}\".format(data.shape[0], time.time()-t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y65WpAQMogRv"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # plot sample of results\n",
    "# from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "# transformed_batch = transformed_batch.numpy()\n",
    "# transformed_batch = np.moveaxis(transformed_batch, 1, 3)\n",
    "\n",
    "# fig = plt.figure(figsize=(15., 15.))\n",
    "# grid = ImageGrid(fig, 111,  \n",
    "#                  nrows_ncols=(4, 4),  \n",
    "#                  axes_pad=0.1)\n",
    "\n",
    "# for ax, im in zip(grid, transformed_batch[0:16]):\n",
    "#     # Iterating over the grid returns the Axes.\n",
    "#     ax.imshow(im)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# del transformed_batch\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "genAugs_onthefly.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
