{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colabMAMLipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHAOTHHLZxD6",
        "outputId": "b32ee9f3-ffc6-4f72-fe54-a3c9d94a7704"
      },
      "source": [
        "#!pip install learn2learn\n",
        "#!pip install torchmeta\n",
        "import torch\n",
        "import utils\n",
        "import model as MODEL\n",
        "import train as TRAIN\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import epoch\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if __name__ == '__main__':\n",
        "    Quincy = False ## set true to run Quincy's model\n",
        "    if Quincy ==True: ## param search in this file doe snot support this \n",
        "        Params = {'datasize':96,'nways':32,'kshots':1,'in_channels':3,\n",
        "                'num_classes':45,'hidden_size':2, \"innerStep\":.0006,\n",
        "                'MetaLR':.0006,\"number_of_tasks\":1, \"Order\":True,\"outerVSinner\": 1,\n",
        "                \"epoch\":50,'aug':True, 'trainvalSplit':.5,'trainvalSplit': .8, 'Quincy':True}\n",
        "    else:\n",
        "        Params = {'Training loss': 126.29095458984375, 'Training Error Rate': 0.3249491751194,\n",
        "                  'Validation topk': 0.7814275622367859, 'Validation Error Rate': 0.5703125, \n",
        "                  'datasize': 96, 'nways': 5, 'kshots': 1, 'in_channels': 3, 'num_classes': 45,\n",
        "                  'hidden_size': 2, 'innerStep': 0.0006, 'MetaLR': 0.0006, 'number_of_tasks': 4, \n",
        "                  'Order': True, 'outerVSinner': 1, 'epoch': 50, 'aug': True, 'Img_size': 96, \n",
        "                  'bs': 32, 'c_dim': 45, 'trainsz': 17718, 'trainvalSplit':.5,'trainvalSplit': .8, 'Quincy':False}\n",
        "    # print('Getting data')\n",
        "    train_tasks,val_loader,test_loader,Params=utils.colabgetdata(Params)\n",
        "\n",
        "   "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/utils.py:229: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  xtest = torch.tensor(test_data).permute(0, 3, 1, 2)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKh1nlD0bZog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b36792e-7d30-40a1-c540-c49895ab1f4b"
      },
      "source": [
        "Params, trainacc, trainloss, valacc, valtopk = epoch.epochthrough(train_tasks,Params,val_loader)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 val accuracy:  0.0865885391831398  topk:  0.23046875\n",
            "epoch: 1 val accuracy:  0.1477864533662796  topk:  0.326171875\n",
            "epoch: 2 val accuracy:  0.16015625  topk:  0.314453125\n",
            "epoch: 3 val accuracy:  0.1673177033662796  topk:  0.3522135317325592\n",
            "epoch: 4 val accuracy:  0.203125  topk:  0.392578125\n",
            "epoch: 5 val accuracy:  0.193359375  topk:  0.388671875\n",
            "epoch: 6 val accuracy:  0.2096354216337204  topk:  0.4029947817325592\n",
            "epoch: 7 val accuracy:  0.2467447966337204  topk:  0.4524739682674408\n",
            "epoch: 8 val accuracy:  0.234375  topk:  0.4342447817325592\n",
            "epoch: 9 val accuracy:  0.2578125  topk:  0.431640625\n",
            "epoch: 10 val accuracy:  0.255859375  topk:  0.4361979067325592\n",
            "epoch: 11 val accuracy:  0.265625  topk:  0.48046875\n",
            "epoch: 12 val accuracy:  0.2623697817325592  topk:  0.4739583432674408\n",
            "epoch: 13 val accuracy:  0.2506510317325592  topk:  0.4739583432674408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY-dwyrrhovK"
      },
      "source": [
        "loss_rate = valacc[-1]\n",
        "reduce = [True,False]\n",
        "nwayss =[32,20,10,5]\n",
        "for i in reduce:\n",
        "    Params['Order']=i\n",
        "    for tasknum in range(4): ## number of tasks inside each outer loop\n",
        "        Params[\"number_of_tasks\"] = int(2**tasknum)\n",
        "        for InoutRatio in range(2): ## ratio of data in outer loop of task to one of the data in tasks right now it is 1:1, 2:1, 3:1\n",
        "            Params['outerVSinner'] = InoutRatio+1\n",
        "            for meta in range(4):## learning rates\n",
        "                Params['MetaLR'] *=(1**(-meta+1))\n",
        "                for innLR in range(4):\n",
        "                    Params[\"innerStep\"] *=(1**(-innLR+1))\n",
        "                    for nwayys in nwayss:\n",
        "                        Params['nways']=nwayys\n",
        "                    model = MODEL.ConvolutionalNeuralNetwork(Params)\n",
        "                    model = model.to(device)\n",
        "                    Atrain = 0\n",
        "                    Ltrain  =0\n",
        "                    Aval = 0\n",
        "                    Akval = 0\n",
        "                    for i in range(Params['epoch']):\n",
        "                        Atrain, Ltrain = TRAIN.train(model, train_tasks,Params, val_loader)\n",
        "                        Aval, Akval = utils.getvalErr(model, val_loader)\n",
        "                        if ((i <= 5) and Aval < .1): ## not to waste time stop early\n",
        "                             break\n",
        "                        if Aval > loss_rate: ## if our val is better then what we had save it\n",
        "                            print(\"found one better\")\n",
        "                            print(loss_rate)\n",
        "                            print(Params)\n",
        "                            dict = {'Training loss': Ltrain, \"Training Error Rate\": Atrain, \"Validation topk\": Akval,\n",
        "                                    \"Validation Error Rate\": Aval}\n",
        "                            tofile = {**dict, **Params}\n",
        "                            with open('/content/drive/MyDrive/Project/BestSoFar.txt', 'a') as f:\n",
        "                                print(tofile, file=f)\n",
        "                                loss_rate = dict[\"Validation Error Rate\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiu2vRK1kTXr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}