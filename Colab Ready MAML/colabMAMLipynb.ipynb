{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colabMAMLipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHAOTHHLZxD6",
        "outputId": "d6e6bf8c-8be2-4266-a745-468ddd4139b5"
      },
      "source": [
        "#!pip install learn2learn\n",
        "#!pip install torchmeta\n",
        "import torch\n",
        "import utils\n",
        "import model as MODEL\n",
        "import train as TRAIN\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if __name__ == '__main__':\n",
        "    Params = {'datasize':96,'nways':32,'kshots':1,'in_channels':3,\n",
        "              'num_classes':45,'hidden_size':2, \"innerStep\":.005,\n",
        "              'MetaLR':.01,\"number_of_tasks\":1, \"Order\":True,\"outerVSinner\": 1,\"epoch\":50,'aug':True}\n",
        "    # print('Getting data')\n",
        "    train_tasks,val_loader,test_loader,Params=utils.colabgetdata(Params)\n",
        "\n",
        "   "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/utils.py:219: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  xtest = torch.tensor(test_data).permute(0, 3, 1, 2)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKh1nlD0bZog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16913293-bd0a-44f4-b1db-77e2b76a302d"
      },
      "source": [
        "model = MODEL.ConvolutionalNeuralNetwork(Params)\n",
        "model = model.to(device)\n",
        "loss_rate=0\n",
        "for i in range(50):\n",
        "    TRAIN.train(model,train_tasks,Params,val_loader)\n",
        "    loss_rate = utils.getvalErr(model,val_loader)[0]\n",
        "print(loss_rate)\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5482954382896423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY-dwyrrhovK"
      },
      "source": [
        "reduce = [True,False]\n",
        "nwayss =[32,20,10,5]\n",
        "for i in reduce:\n",
        "    Params['Order']=i\n",
        "    for tasknum in range(4): ## number of tasks inside each outer loop\n",
        "        Params[\"number_of_tasks\"] = int(2**tasknum)\n",
        "        for InoutRatio in range(2): ## ratio of data in outer loop of task to one of the data in tasks right now it is 1:1, 2:1, 3:1\n",
        "            Params['outerVSinner'] = InoutRatio+1\n",
        "            for meta in range(4):## learning rates\n",
        "                Params['MetaLR'] *=(1**(-meta+1))\n",
        "                for innLR in range(4):\n",
        "                    Params[\"innerStep\"] *=(1**(-innLR+1))\n",
        "                    for nwayys in nwayss:\n",
        "                        Params['nways']=nwayys\n",
        "                    model = MODEL.ConvolutionalNeuralNetwork(Params)\n",
        "                    model = model.to(device)\n",
        "                    Atrain = 0\n",
        "                    Ltrain  =0\n",
        "                    Aval = 0\n",
        "                    Akval = 0\n",
        "                    for i in range(Params['epoch']):\n",
        "                        Atrain, Ltrain = TRAIN.train(model, train_tasks,Params, val_loader)\n",
        "                        Aval, Akval = utils.getvalErr(model, val_loader)\n",
        "                        if ((i <= 3) and Aval < .1): ## not to waste time stop early\n",
        "                             break\n",
        "                        if Aval > loss_rate: ## if our val is better then what we had save it\n",
        "                            print(\"found one better\")\n",
        "                            print(loss_rate)\n",
        "                            print(Params)\n",
        "                            dict = {'Training loss': Ltrain, \"Training Error Rate\": Atrain, \"Validation topk\": Akval,\n",
        "                                    \"Validation Error Rate\": Aval}\n",
        "                            tofile = {**dict, **Params}\n",
        "                            with open('/content/drive/MyDrive/Project/BestSoFar.txt', 'w') as f:\n",
        "                                print(tofile, file=f)\n",
        "                                loss_rate = dict[\"Validation Error Rate\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiu2vRK1kTXr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}